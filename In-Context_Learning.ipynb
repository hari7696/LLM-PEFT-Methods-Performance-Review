{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ghari\\anaconda3\\envs\\llm\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch\n",
    "import torchdata\n",
    "import transformers\n",
    "import datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch versio 2.3.1+cpu\n",
      "torchdata version 0.7.1\n",
      "transformers version 4.42.4\n",
      "datasets version 2.20.0\n"
     ]
    }
   ],
   "source": [
    "print(\"torch versio\", torch.__version__)\n",
    "print(\"torchdata version\", torchdata.__version__ )\n",
    "print(\"transformers version\", transformers.__version__ )\n",
    "print(\"datasets version\", datasets.__version__ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dialogue summarzation dataset and evaluating the baseline performance\n",
    "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
    "dialogue_dataset = datasets.load_dataset(huggingface_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Dialogue: \n",
      " #Person1#: Kate, you never believe what's happened.\n",
      "#Person2#: What do you mean?\n",
      "#Person1#: Masha and Hero are getting divorced.\n",
      "#Person2#: You are kidding. What happened?\n",
      "#Person1#: Well, I don't really know, but I heard that they are having a separation for 2 months, and filed for divorce.\n",
      "#Person2#: That's really surprising. I always thought they are well matched. What about the kids? Who get custody?\n",
      "#Person1#: Masha, it seems quiet and makable, no quarrelling about who get the house and stock and then contesting the divorce with other details worked out.\n",
      "#Person2#: That's the change from all the back stepping we usually hear about. Well, I still can't believe it, Masha and Hero, the perfect couple. When would they divorce be final?\n",
      "#Person1#: Early in the New Year I guess.\n",
      "--------------------\n",
      "Summary : \n",
      " #Person1# tells Kate that Masha and Hero are getting a peaceful divorce. Kate feels surprised and asks about their kids.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Dialogue: \n",
      " #Person1#: I've had it! I am done working for a company that is taking me nowhere!\n",
      "#Person2#: So what are you gonna do? Just quit?\n",
      "#Person1#: That's exactly what I am going to do! I have decided to create my own company! I am going to write up a business plan, get some investors and start working for myself!\n",
      "#Person2#: Have you ever written up a business plan before?\n",
      "#Person1#: Well, no, it can't be that hard! I mean, all you have to do is explain your business, how you are going to do things and that's it, right?\n",
      "#Person2#: You couldn't be more wrong! A well written business plan will include an executive summary which highlights the idea of the business in two pages or less. Then you need to describe your company with information such as what type of legal structure it has, history, etc.\n",
      "#Person1#: Well, that seems easy enough.\n",
      "#Person2#: Wait, there is more! Then you need to introduce and describe your goods or services. What they are and how they are different from competitors? Then comes the hard part, a market analysis. You need to investigate and analyze hundreds of variables! You need to take into consideration socioeconomic factors from GDP per capita to how many children on average the population has! All this information is useful so that you can move on to your strategy and implementation stage, where you will describe in detail how you will actually execute your idea.\n",
      "#Person1#: Geez. Is that all?\n",
      "#Person2#: Almost, the most important piece of information for your investors will be the financial analysis. Here you will calculate and estimate sales, cash flow and profits. After all, people will want to know when they will begin to see a return on their investment!\n",
      "#Person1#: Umm. I think I ' ll just stick to my old job and save myself all the hassle of trying to start up a business!\n",
      "--------------------\n",
      "Summary : \n",
      " #Person1# wants to start #Person1#'s own business, but #Person2# warns #Person1# of the hassle. #Person2# tells #Person1# what is needed in a business plan and #Person1# decides to stick to the old job for now.\n"
     ]
    }
   ],
   "source": [
    "# checking data\n",
    "from utilities import print_line, save_pickle, load_pickle\n",
    "indexes = [7, 17]\n",
    "for id in indexes:\n",
    "    sample = dialogue_dataset['test'][id]\n",
    "    print_line(100)\n",
    "    print_line(100)\n",
    "    print(\"Dialogue: \\n\",sample['dialogue'])\n",
    "    print_line(20)\n",
    "    print(\"Summary : \\n\", sample['summary'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creatig benchmakrs for in-context leaning and LoRa, IA3\n",
    "\n",
    "model_name='google/flan-t5-base'\n",
    "model_name = \"google/flan-t5-large\"\n",
    "\n",
    "model = transformers.AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name, use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zero shot Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def make_prompt_template(dialogue):\n",
    "\n",
    "    return f\"\"\"\n",
    "Dialogue :\n",
    "    {dialogue}\n",
    "Summary: \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "dict_results_holder = {}\n",
    "\n",
    "np.random.seed(7)\n",
    "samples_ids = np.random.randint(100, 250, 10)\n",
    "samples_ids = [int(item) for item in samples_ids]\n",
    "\n",
    "for id in samples_ids:\n",
    "    dict_results_holder[id] = {}\n",
    "    example = dialogue_dataset['test'][id]\n",
    "    dict_results_holder[id]['Human_summary'] = example['summary']\n",
    "\n",
    "    tokenized_sentence = tokenizer(make_prompt_template(example['dialogue']), return_tensors='pt') # type: ignore\n",
    "\n",
    "    sentence_decoded = tokenizer.decode( model.generate(tokenized_sentence['input_ids'], max_new_tokens=100)[0], skip_special_tokens= True)\n",
    "\n",
    "    dict_results_holder[id]['zeroshot'] = sentence_decoded "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def make_icl_prompt_template(dialogue):\n",
    "    \n",
    "    onshot_sample = dialogue_dataset['test'][0] \n",
    "    return f\"\"\"\n",
    "Dialogue :\n",
    "    {onshot_sample['dialogue']}\n",
    "Summary: \n",
    "    {onshot_sample['summary']}\n",
    "    \n",
    "Dialogue :\n",
    "    {dialogue}\n",
    "Summary: \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for id in samples_ids:\n",
    "    if id not in dict_results_holder.keys():\n",
    "        dict_results_holder[id] = {}\n",
    "\n",
    "    example = dialogue_dataset['test'][id]\n",
    "    dict_results_holder[id]['Human_summary'] = example['summary']\n",
    "\n",
    "    tokenized_sentence = tokenizer(make_icl_prompt_template(example['dialogue']), return_tensors='pt') # type: ignore\n",
    "\n",
    "    sentence_decoded = tokenizer.decode( model.generate(tokenized_sentence['input_ids'], max_new_tokens=100)[0], skip_special_tokens= True)\n",
    "\n",
    "    dict_results_holder[id]['one_shot'] = sentence_decoded \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def make_icl_few_shot_prompt_template(dialogue):\n",
    "    \n",
    "    prompt_str = \"\"\n",
    "    fewshot_ids = [int(item) for item in np.random.randint(300, 500, 4)]\n",
    "    for id in fewshot_ids:\n",
    "        sample = dialogue_dataset['test'][id] \n",
    "        prompt_str += f\"\"\"\n",
    "Dialogue :\n",
    "    {sample['dialogue']}\n",
    "Summary: \n",
    "    {sample['summary']}\n",
    "\n",
    "\"\"\"\n",
    "    prompt_str += f\"\"\"\n",
    "Dialogue :\n",
    "    {dialogue}\n",
    "Summary: \n",
    "\"\"\"\n",
    "    return prompt_str\n",
    "        \n",
    "\n",
    "\n",
    "for id in samples_ids:\n",
    "    if id not in dict_results_holder.keys():\n",
    "        dict_results_holder[id] = {}\n",
    "\n",
    "    example = dialogue_dataset['test'][id]\n",
    "    dict_results_holder[id]['Human_summary'] = example['summary']\n",
    "\n",
    "    tokenized_sentence = tokenizer(make_icl_few_shot_prompt_template(example['dialogue']), return_tensors='pt') # type: ignore\n",
    "\n",
    "    sentence_decoded = tokenizer.decode( model.generate(tokenized_sentence['input_ids'], max_new_tokens=100)[0], skip_special_tokens= True)\n",
    "\n",
    "    dict_results_holder[id]['few_shot'] = sentence_decoded \n",
    "\n",
    "save_pickle(dict_results_holder, 'dict_results_holder.pickle' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rouge_scores(dict_results_holder):\n",
    "    human_references = [dict_results_holder[key]['Human_summary'] for key in dict_results_holder.keys()]\n",
    "    zeroshot = [dict_results_holder[key]['zeroshot'] for key in dict_results_holder.keys()]\n",
    "    oneshot = [dict_results_holder[key]['one_shot'] for key in dict_results_holder.keys()]\n",
    "    fewshot = [dict_results_holder[key]['few_shot'] for key in dict_results_holder.keys()]\n",
    "\n",
    "    import evaluate\n",
    "    rouge = evaluate.load('rouge')\n",
    "    zeroshot_rouge = rouge.compute(\n",
    "        predictions=zeroshot,\n",
    "        references=human_references,\n",
    "        use_aggregator=True,\n",
    "        use_stemmer=True,\n",
    "    )\n",
    "\n",
    "    oneshot_rouge = rouge.compute(\n",
    "        predictions=oneshot,\n",
    "        references=human_references,\n",
    "        use_aggregator=True,\n",
    "        use_stemmer=True,\n",
    "    )\n",
    "\n",
    "    fewshot_rouge = rouge.compute(\n",
    "        predictions=fewshot,\n",
    "        references=human_references,\n",
    "        use_aggregator=True,\n",
    "        use_stemmer=True,\n",
    "    )\n",
    "\n",
    "    print( \"zero_short : {} \\n one_short : {} \\n  few_short : {} \\n\".format(zeroshot_rouge, oneshot_rouge, fewshot_rouge))\n",
    "\n",
    "\n",
    "\n",
    "#rouge.compute(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RougeScore calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BASE Rouge scores\n",
      "zero_short : {'rouge1': 0.2714693191931299, 'rouge2': 0.08819247759237706, 'rougeL': 0.23776439735098698, 'rougeLsum': 0.23957339051104468} \n",
      " one_short : {'rouge1': 0.21037399988098748, 'rouge2': 0.05469353119567932, 'rougeL': 0.18559400317231328, 'rougeLsum': 0.18686672342728244} \n",
      "  few_short : {'rouge1': 0.25296282344297, 'rouge2': 0.07823249760548293, 'rougeL': 0.2276731230434858, 'rougeLsum': 0.22920094244492306} \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "T5 Large Rouge scores\n",
      "zero_short : {'rouge1': 0.3066088576230827, 'rouge2': 0.10692799150952427, 'rougeL': 0.25387967561041735, 'rougeLsum': 0.2528241077739247} \n",
      " one_short : {'rouge1': 0.30304847492450127, 'rouge2': 0.10420114942528737, 'rougeL': 0.25381356374884556, 'rougeLsum': 0.2504161782905666} \n",
      "  few_short : {'rouge1': 0.29064035082369977, 'rouge2': 0.11957729468599035, 'rougeL': 0.2546831696546925, 'rougeLsum': 0.25404069809116836} \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"T5 BASE Rouge scores\")\n",
    "dict_results_holder = load_pickle('t5_base_ICL_dict_results_holder.pickle')\n",
    "get_rouge_scores(dict_results_holder)\n",
    "print_line(100)\n",
    "\n",
    "print(\"T5 Large Rouge scores\")\n",
    "dict_results_holder = load_pickle('t5_large_ICL_dict_results_holder.pickle')\n",
    "get_rouge_scores(dict_results_holder)\n",
    "print_line(100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "* The results for t5-base model[220M], makes some sense, the smaller size models arent exactly great at ICL. Ideally the scores are supposed to improve with one shot and few shot ICL but across the scores, zero shot is the winner. \n",
    "* with t5 large model[770M], As expected there is slight improvement in >rouge1 scores because its a lrage model relatively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
